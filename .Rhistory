getwd()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
library(stringr)
library(purrr)
library(knitr)
library(forcats)
library(tidyr)
library(stm, quietly = TRUE)
library(quanteda, quietly = TRUE)
library(broom)
library(tidytext)
# maybe topicmodels? tidydtext
# Chunk 2
pub_com <- read_csv(dir("data", pattern = "csv", full.names = TRUE),
guess_max = 2000,
show_col_types = FALSE) |>
rename_with(tolower) |>
rename_with(str_replace_all, pattern = " ", replacement = "_") |>
select( -where(\(x) all(is.na(x)))) |>
select(-first_name, last_name)
# Chunk 3
paste(1:5, ":" , str_trunc(pub_com[sample(nrow(pub_com), 5), ]$comment, 300)) |>
cat(sep = "\n\n")
# Chunk 4
pub_com <- mutate(
pub_com,
category = replace_na(category, "(Missing)") |>
factor() |>
fct_lump_prop(prop = .01, other_level = "All other") |>
fct_recode("Institution of Higher Education"  =
"Four-Year Public Institution of Higher Education",
"Institution of Higher Education" =
"Private/For-Profit Institution of Higher Education")
)
count(pub_com, category, sort = TRUE) |>
mutate(p = n / sum(n) * 100) |>
kable(digits = 2)
# Chunk 5
pub_com <- select(pub_com, category, comment) |>
filter(category %in% c("Student", "Institution of Higher Education")) |>
mutate(
category = factor(category,
levels = c("Student",
"Institution of Higher Education")),
doc_id = row_number())
# Chunk 6
pub_com_dfm <- mutate(pub_com, comment = tolower(comment)) |>
corpus(docid_field = "doc_id",
text_field = "comment",
meta = list("category")) |>
tokens(what = "word",
remove_punct = TRUE,
remove_numbers = TRUE, # this won't remove e.g. "15k" or "1st"
remove_separators = TRUE,
split_hyphens = TRUE,
include_docvars = TRUE) |>
tokens_remove(c(stopwords("english", source = "smart"))) |>
tokens_wordstem() |>
dfm()
convert(pub_com_dfm, "data.frame") |>
as_tibble() |>
head()
# Chunk 7
k <- 5
# Chunk 8
if (!file.exists("data/pub_com_files.rds")) {
pub_com_stm <- stm(
pub_com_dfm,
K = k,
init.type = "Spectral",
prevalence = ~category,
content = ~category,
verbose = FALSE)
write_rds(
list(
"data" = pub_com,
"dfm" = pub_com_dfm,
"stm" = pub_com_stm),
"data/pub_com_files.rds")
} else {
pub_com_stm <- read_rds("data/pub_com_files.rds")$stm
}
# Chunk 9
n_terms <- 10
top_terms <- tibble(x = replicate(3, pub_com_stm, simplify = FALSE),
matrix = c("beta", "beta", "frex")) |>
pmap(tidy) |>
set_names("beta", "beta_grpd", "frex") |>
map(group_by, topic) |>
map_at("beta_grpd", group_by, y.level, .add = TRUE) |>
map_at(c("beta", "beta_grpd"), \(x) slice_max(x, beta, n = 25) |>
distinct(term, .keep_all = TRUE)) |>
map(slice, 1:n_terms) |>
map(summarize,
label =  paste0(term, collapse = ", "))
gammas <- tidy(pub_com_stm, "gamma") |>
summarize(gamma_avg = mean(gamma), .by = topic) |>
left_join(top_terms$beta, by = "topic") |>
left_join(top_terms$frex, by = "topic") |>
mutate(
label_full = paste0("Topic ", topic, ": ", label.x, "\n",
"FREX:", label.y),
label_short = paste0("Topic ", topic, ": ", str_trunc(label.x, 30),
" | FREX: ", str_trunc(label.y, 30)),
label.x = NULL,
label.y = NULL,
topic = factor(topic) |>
fct_reorder(gamma_avg))
ggplot(gammas, aes(x = topic, y = gamma_avg)) +
geom_col(width = .05, fill = "steelblue4") +
geom_text(aes(label = label_full), nudge_y = .125) +
coord_flip() +
theme_minimal(base_size = 12) +
theme(
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
axis.text.y = element_blank())  +
scale_y_continuous(limits = c(0, .75)) +
labs(title = paste("Top", n_terms, "terms in", k, "topics among public comments to Student Debt Relief"),
x = NULL,
y = "Avg. gamma")
ggsave("top_terms.svg")
ggsave("top_terms.svg", width = 16, height = 8, units = "in")
![](top_terms.svg)
